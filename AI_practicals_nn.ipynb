{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP0TTjo2IHcx"
      },
      "source": [
        "Deep Learning: Practical session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVUwqOFb2vPA"
      },
      "source": [
        "## global settings\n",
        "\n",
        "For faster processing, make sure to set in *Runtime > Change runtime type*, *hardware accelerator* to *GPU*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NelzDOpCgtJi"
      },
      "source": [
        "##Usefull packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSrwJX4S0Ii3"
      },
      "source": [
        "### Tensorflow and Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgRGzNEHh0Ee"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0yduGuahNkh"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "print('Tensorflow version:')\n",
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il77nNxjgsTk"
      },
      "source": [
        "import datetime, os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, InputLayer\n",
        "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "precision, recall = Precision(), Recall()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swisGM3dhew1"
      },
      "source": [
        "## Downloading database\n",
        "\n",
        "Follow the instructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AweEjqfh0hL"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, files\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvoHODGLhcIx"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "googledrive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35XxJhJArtV"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R7uTeV5Bk4C"
      },
      "source": [
        "id = '17T6-1E6Nk37O6S6sUhprQvTfLYmXQb-b'\n",
        "download = googledrive.CreateFile({'id': id})\n",
        "download.GetContentFile('2021_fruits_dataset.zip')\n",
        "!unzip '2021_fruits_dataset.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjgUQifPbfzP"
      },
      "source": [
        "# Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUdYV2db0lW-"
      },
      "source": [
        "class_names = ['apple', 'banana', 'cherry', 'grape', 'onion', 'peach', 'pear', 'pepper', 'plum', 'potato', 'tomato']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShkD0cdb4Ee"
      },
      "source": [
        "# rescale images to range [0; 1]\n",
        "def im_preprocess(im):\n",
        "\n",
        "    if im.max() > 1.:\n",
        "        # to float instead of uint8\n",
        "        im = np.divide(im, 255., dtype=np.float16)\n",
        "\n",
        "    assert im.max() <= 1.\n",
        "\n",
        "    return im\n",
        "\n",
        " \n",
        "def get_data(dataset, factor_downsample = 1):\n",
        "    \"\"\"\n",
        "    :param factor_downsample: skips images to reduce dataset size\n",
        "    \"\"\"\n",
        "\n",
        "    assert dataset in ['training', 'validation', 'testing']\n",
        "\n",
        "    print(f'Loading {dataset}-dataset')\n",
        "\n",
        "    if dataset == 'training':\n",
        "        home_folder = '2021_fruits_dataset/1training'\n",
        "    elif dataset == 'validation':\n",
        "        home_folder = '2021_fruits_dataset/2validation'\n",
        "    else:\n",
        "        home_folder = '2021_fruits_dataset/3test'\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    folder_list = sorted(os.listdir(home_folder))\n",
        "\n",
        "    for folder in folder_list:\n",
        "        folder_lower = folder.lower()\n",
        "\n",
        "        if 'apple' == folder_lower[:5]:            \n",
        "            y_index = class_names.index('apple')\n",
        "        \n",
        "        elif 'banana' in folder_lower:\n",
        "            y_index = class_names.index('banana')\n",
        "            \n",
        "        elif 'cherry' in folder_lower[:6]:\n",
        "            y_index = class_names.index('cherry')\n",
        "            \n",
        "        elif 'grape ' in folder_lower:\n",
        "            y_index = class_names.index('grape')\n",
        "            \n",
        "        elif 'onion' in folder_lower:\n",
        "            y_index = class_names.index('onion')\n",
        "            \n",
        "        elif 'peach' in folder_lower:\n",
        "            y_index = class_names.index('peach')\n",
        "            \n",
        "        elif 'pear' in folder_lower:\n",
        "            y_index = class_names.index('pear')\n",
        "\n",
        "        elif 'pepper' in folder_lower:\n",
        "            y_index = class_names.index('pepper')\n",
        "            \n",
        "        elif 'plum' in folder_lower:\n",
        "            y_index = class_names.index('plum')\n",
        "            \n",
        "        elif 'potato' in folder_lower:\n",
        "            y_index = class_names.index('potato')\n",
        "            \n",
        "        elif 'tomato' in folder_lower:\n",
        "            y_index = class_names.index('tomato')\n",
        "        else:\n",
        "            # Not included in assignment\n",
        "            raise ValueError(f'Unknown class in {folder_lower}')\n",
        "            continue\n",
        "\n",
        "        folder_path = os.path.join(home_folder, folder)\n",
        "        file_list = sorted(os.listdir(folder_path))\n",
        "        for im_file in file_list:\n",
        "            \n",
        "            name, _ = os.path.splitext(im_file)\n",
        "            index_file = int(name.split('_')[-2])   # Second to last! Last element is width image (=100)\n",
        "            if (index_file % factor_downsample) != 0:\n",
        "                continue\n",
        "        \n",
        "            im_path = os.path.join(folder_path, im_file)\n",
        "\n",
        "            im = plt.imread(im_path)\n",
        "            im = im_preprocess(im)\n",
        "\n",
        "            x.append(im)\n",
        "            y.append(y_index)\n",
        "\n",
        "    print(f'Finished {dataset}-dataset')\n",
        "    return x, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDH1Qc-abg99"
      },
      "source": [
        "print(class_names)\n",
        "\n",
        "print('Training data')\n",
        "x_train, y_train = get_data('training', factor_downsample = 1)\n",
        "x_valid, y_valid = get_data('validation', factor_downsample = 1)\n",
        "x_test, y_test = get_data('testing', factor_downsample = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyh-k6lhow8d"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLJxgiNZmqTe"
      },
      "source": [
        "x_train = np.stack(x_train, axis=0).astype(np.float16)\n",
        "x_valid = np.stack(x_valid, axis=0).astype(np.float16)\n",
        "x_test = np.stack(x_test, axis=0).astype(np.float16)\n",
        "\n",
        "y_train = np.stack(y_train, axis=0).astype(np.int16)\n",
        "y_valid = np.stack(y_valid, axis=0).astype(np.int16)\n",
        "y_test = np.stack(y_test, axis=0).astype(np.int16)\n",
        "\n",
        "\n",
        "index = [i for i in range(len(x_train))]\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(index)\n",
        "selected_index = index[0: int(len(index)/2)]\n",
        "x_train = x_train[selected_index,:,:,:]\n",
        "y_train = y_train[selected_index]\n",
        "\n",
        "index_valid = [i for i in range(len(x_valid))]\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(index_valid)\n",
        "selected_index_valid = index_valid[0: int(len(index_valid)/2)]\n",
        "x_valid = x_valid[selected_index_valid,:,:,:]\n",
        "y_valid = y_valid[selected_index_valid]\n",
        "\n",
        "index_test = [i for i in range(len(x_test))]\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(index_test)\n",
        "selected_index_test = index_test[0: int(len(index_test)/2)]\n",
        "x_test = x_test[selected_index_test,:,:,:]\n",
        "y_test = y_test[selected_index_test]\n",
        "\n",
        "\n",
        "\n",
        "def y_to_apple(y):\n",
        "    i_apple = class_names.index('apple')\n",
        "    y_apple = np.equal(y, i_apple, dtype=np.int16)\n",
        "    return y_apple\n",
        "\n",
        "y_train_apple = y_to_apple(y_train)\n",
        "y_valid_apple = y_to_apple(y_valid)\n",
        "y_test_apple = y_to_apple(y_test)\n",
        "\n",
        "y_train_fruit = to_categorical(y_train, num_classes=None)\n",
        "y_valid_fruit = to_categorical(y_valid, num_classes=None)\n",
        "y_test_fruit = to_categorical(y_test, num_classes=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FLKD5pdofZ6"
      },
      "source": [
        "## Building a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiYy_2hNBRz5"
      },
      "source": [
        "pract_folder = 'drive/My Drive/AI_pract3_nn2021'\n",
        "logs_folder = os.path.join(pract_folder, 'logs')\n",
        "weights_folder = os.path.join(pract_folder, 'weights')\n",
        "if not os.path.exists(weights_folder):\n",
        "    os.makedirs(weights_folder)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYA0EJ-zolNu"
      },
      "source": [
        "def get_model_base_simple(k = 4):  \n",
        "    model = Sequential()\n",
        "    model.epoch = 0     # to save amount of epochs trained\n",
        "\n",
        "    model.add(InputLayer((100, 100, 3)))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2))) # downsampling\n",
        "    model.add(Conv2D(k, (3, 3), activation='elu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(k, (3, 3), activation='elu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(k, (4, 4), activation='elu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(k, activation='elu'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_model_apple_simple(lr, loss='mse'):\n",
        "  \n",
        "    model = get_model_base_simple()\n",
        "\n",
        "    # single class classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss=loss,\n",
        "                optimizer=SGD(lr),\n",
        "                metrics=['accuracy', precision, recall])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_model_fruit_simple(lr):\n",
        "    model = get_model_base_simple()\n",
        "  \n",
        "    ### To implement yourself\n",
        "    model.add(None)\n",
        "    model.compile(loss=None,\n",
        "                optimizer=SGD(lr),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeINypx5yIhE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-zqmB3EpFj4"
      },
      "source": [
        "## Apples or not apples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPr0feKUpg6f"
      },
      "source": [
        "model_apple = get_model_apple_simple(lr=1e-2)\n",
        "\n",
        "### uncomment if you already have a trained network\n",
        "# model_apple = keras.models.load_model(os.path.join(weights_folder, '<apple.hdf5>'))\n",
        "\n",
        "model_apple.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-AqW-yo5Oi"
      },
      "source": [
        "Training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLUQGFTOoOK7"
      },
      "source": [
        "model_apple.fit(x_train, y_train_apple, validation_data=(x_valid, y_valid_apple), batch_size=32, epochs=20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "f30A3cBIfeGx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM8knTrDwjrZ"
      },
      "source": [
        "y_test_pred = model_apple.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flNrtOxp1VJF"
      },
      "source": [
        "###Saving and downloading model.\n",
        "\n",
        "Alternatively you can download it manually through: *View -> Table of contents -> Files -> Right click* **.h5-> Download*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932mtVjs1KOg"
      },
      "source": [
        "path = os.path.join(weights_folder, 'apple.h5')\n",
        "model_apple.save(path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8pTIAmKL29f"
      },
      "source": [
        "## Fruit classifcation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfACQCMtL45T"
      },
      "source": [
        "# to implement\n",
        "def get_model_fruit_simple():\n",
        "  return None\n",
        "\n",
        "model_fruit = get_model_fruit_simple()\n",
        "\n",
        "model_fruit.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-B_HtqZNtPh"
      },
      "source": [
        "# train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWq2N5EoRuTu"
      },
      "source": [
        "# Testing on own data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCTJNVtnlh3f"
      },
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PFMFLv0QtfN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bwd2dAVQ4Ne"
      },
      "source": [
        "url = 'https://images-na.ssl-images-amazon.com/images/I/319J7YpfyNL.jpg'\n",
        "\n",
        "def open_image(path):\n",
        "\n",
        "    response = requests.get(path)\n",
        "    img = np.array(Image.open(BytesIO(response.content)))\n",
        "\n",
        "    resize = cv2.resize(img, (100, 100))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(resize)\n",
        "    plt.plot()\n",
        "\n",
        "    single_x = np.stack([resize], axis=0)\n",
        "    im_resize = im_preprocess(single_x)\n",
        "\n",
        "    # TODO preprocessing \n",
        "    ...\n",
        "\n",
        "    return im_resize\n",
        "\n",
        "single_x = open_image(url) # '<your_fruit.jpg>'\n",
        "\n",
        "model_apple = load_model(weights_folder + '/<model_apple>.hdf5')\n",
        "model_fruit = load_model(weights_folder + '/<model_fruit>.hdf5')\n",
        "\n",
        "pred_apple = model_apple.predict(single_x)\n",
        "pred_fruit = model_fruit.predict(single_x)\n",
        "\n",
        "print(pred_apple)\n",
        "print(pred_fruit)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}